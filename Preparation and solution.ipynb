{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc491dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0280c0",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2bd0d",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bc4ab",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df[\"is_in_yandex\"] = pd.Categorical(df[\"is_in_yandex\"])\n",
    "df[\"is_in_yandex\"].astype('category').cat.codes\n",
    "df[\"is_in_yandex\"] = df[\"is_in_yandex\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b893e36",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df[\"is_return\"] = pd.Categorical(df[\"is_return\"])\n",
    "df[\"is_return\"].astype('category').cat.codes\n",
    "df[\"is_return\"] = df[\"is_return\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824e7b4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def op_t(x):\n",
    "    return x[:x.find('_')]\n",
    "def op_a(x):\n",
    "    return x[x.find('_')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23deb7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['op_t'] = df['oper_type + oper_attr'].apply(op_t).astype('int64')\n",
    "df['op_a'] = df['oper_type + oper_attr'].apply(op_a).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865df68",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def p_to_int(x):\n",
    "    if type(x) == float:\n",
    "        return int(x)\n",
    "    return x[:x.find('.')]\n",
    "\n",
    "df['index_oper'] = df['index_oper'].apply(p_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714818b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df['priority'] = df['priority'].apply(p_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0939bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = pd.read_csv('PIndx20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq['index_oper'] = qq['INDEX'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    x = int(x)\n",
    "    if x // 10**5 >0:\n",
    "        return 6\n",
    "    elif x // 10**4 >0:\n",
    "        return 5\n",
    "    elif x // 10**3 >0:\n",
    "        return 4\n",
    "\n",
    "def from5t6(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    x = int(x)\n",
    "    if x // 10**5 == 0:\n",
    "        return x*10\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = pd.merge(df[['index_oper','index_oper2']], qq[['index_oper2','ACTDATE']],how = 'left', on=\"index_oper2\")\n",
    "po = pd.merge(df[['index_oper','index_oper3']], qq[['index_oper3','ACTDATE']],how = 'left', on=\"index_oper3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pld2 = pd.DataFrame(columns = ['index_oper','new_index_oper','OPSSUBM','REGION','AUTONOM','CITY','ACTDATE'])\n",
    "pld = pd.DataFrame(columns = ['index_oper','new_index_oper'])\n",
    "pld['index_oper'] = df['index_oper'].values\n",
    "pld2['index_oper'] = df['index_oper'].values\n",
    "qq['new_index_oper'] = qq['INDEX'].values\n",
    "\n",
    "for i in range(10):\n",
    "    def from5t6(x):\n",
    "        if x == '':\n",
    "            return 0\n",
    "        x = int(x)\n",
    "        if x // 10**5 == 0:\n",
    "            return x*10 + i\n",
    "        return x\n",
    "    pld['new_index_oper'] = pld['index_oper'].apply(from5t6)\n",
    "    pld2['new_index_oper'] = pld2['index_oper'].apply(from5t6)\n",
    "    \n",
    "    pz = pd.merge(pld, qq[['new_index_oper','OPSSUBM','REGION','AUTONOM','CITY','ACTDATE']],how = 'left', on=\"new_index_oper\")\n",
    "    \n",
    "    pld['index_oper'][pz['ACTDATE'].isna() == False]['index_oper'] = pz[pz['ACTDATE'].isna() == False]['new_index_oper'].values\n",
    "    pld2['index_oper'][pz['ACTDATE'].isna() == False]['index_oper'] = pz[pz['ACTDATE'].isna() == False]['new_index_oper'].values\n",
    "    \n",
    "    pld2.loc[pz['ACTDATE'].isna() == False,['OPSSUBM','REGION','AUTONOM','CITY','ACTDATE']] = pz[pz['ACTDATE'].isna() == False][['OPSSUBM','REGION','AUTONOM','CITY','ACTDATE']].values\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pld2[pld2['index_oper'] == 641769] = [[641769,641769,641760,'КУРГАНСКАЯ ОБЛАСТЬ','','ДАЛМАТОВО','2021-01-01'] for i in range(54)]\n",
    "pld2[pld2['index_oper'] == '64142'] = [[641420,641420,641420,'КУРГАНСКАЯ ОБЛАСТЬ','','ЗВЕРИНОГОЛОВСКОЕ','2021-01-01'] for i in range(38)]\n",
    "pld2[pld2['index_oper'] == 630301] = [[630300,630300,630300,'НОВОСИБИРСКАЯ ОБЛАСТЬ','','НОВОСИБИРСК','2021-01-01'] for i in range(36)]\n",
    "pld2[pld2['index_oper'] == '62608'] = [[626080,626080,626080,'ТЮМЕНСКАЯ ОБЛАСТЬ','','ИСЕТСКОЕ','2021-01-01'] for i in range(30)]\n",
    "pld2[pld2['index_oper'] == 626089] = [[626080,626080,626080,'ТЮМЕНСКАЯ ОБЛАСТЬ','','ИСЕТСКОЕ','2021-01-01'] for i in range(19)]\n",
    "pld2[pld2['index_oper'] == 641429] = [[641420,641420,641420,'КУРГАНСКАЯ ОБЛАСТЬ','','ЗВЕРИНОГОЛОВСКОЕ','2021-01-01'] for i in range(17)]\n",
    "pld2[pld2['index_oper'] == 356247] = [[356247,356247,356240,'СТАВРОПОЛЬСКИЙ КРАЙ','','МИХАЙЛОВСКОЕ','2021-01-01'] for i in range(2)]\n",
    "\n",
    "df.drop(['index_oper2','index_oper3'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4df5d",
   "metadata": {},
   "source": [
    "save in ('big_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d21d7",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.read_csv('big_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df.drop(['Unnamed: 0'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8183dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['net_weight'] = (big_df['weight'] - big_df['weight_mfi'])\n",
    "big_df['total_price'] = (big_df['price_mfi'] + big_df['transport_pay'])\n",
    "\n",
    "big_df['w/p'] = np.log(big_df['weight_mfi'] + 1) - np.log(big_df['price_mfi']+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8fcf0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_df['post_days'] = pd.to_datetime('2020-11-1') - pd.to_datetime(big_df['ACTDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ef863",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_df['post_days'] = big_df['post_days'].apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890869fa",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_df['delta_log1'] = np.log(big_df['total_qty_oper_login_1']+1) - np.log(big_df['dist_qty_oper_login_1']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c22ff",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_df['delta_qty_log'] = (big_df['total_qty_oper_login_1'] - big_df['total_qty_oper_login_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c5645",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_df['delta_bigi'] = (big_df['total_qty_over_index'] - big_df['total_qty_over_index_and_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9aadd3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def num_tov(x):\n",
    "    if x == '0' or x=='':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count(',')+1\n",
    "    \n",
    "\n",
    "big_df['num_prod'] = big_df['name_mfi'].apply(num_tov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq['index_oper'] = qq['INDEX'].values\n",
    "def p_to_int(x):\n",
    "    if type(x) == float:\n",
    "        return int(x)\n",
    "    return x[:x.find('.')]\n",
    "\n",
    "\n",
    "def nd(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    x = int(x)\n",
    "    if x // 10**5 >0:\n",
    "        return 6\n",
    "    elif x // 10**4 >0:\n",
    "        return 5\n",
    "    elif x // 10**3 >0:\n",
    "        return 4\n",
    "\n",
    "def from5t6(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    x = int(x)\n",
    "    if x // 10**5 == 0:\n",
    "        return x*10\n",
    "    return x\n",
    "\n",
    "\n",
    "def nd(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    x = int(x)\n",
    "    if x // 10**5 >0:\n",
    "        return 6\n",
    "    elif x // 10**4 >0:\n",
    "        return 5\n",
    "    elif x // 10**3 >0:\n",
    "        return 4\n",
    "\n",
    "def from5t6(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    x = int(x)\n",
    "    if x // 10**5 == 0:\n",
    "        return x*10\n",
    "    return x\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "test_df['index_oper'] = test_df['index_oper'].apply(p_to_int)\n",
    "\n",
    "\n",
    "pld2 = pd.DataFrame(columns = ['index_oper','new_index_oper','OPSSUBM','REGION','AUTONOM','CITY','ACTDATE'])\n",
    "pld = pd.DataFrame(columns = ['index_oper','new_index_oper'])\n",
    "pld['index_oper'] = test_df['index_oper'].values\n",
    "pld2['index_oper'] = test_df['index_oper'].values\n",
    "qq['new_index_oper'] = qq['INDEX'].values\n",
    "\n",
    "for i in range(10):\n",
    "    def from5t6(x):\n",
    "        if x == '':\n",
    "            return 0\n",
    "        x = int(float(x))\n",
    "        if x // 10**5 == 0:\n",
    "            return x*10 + i\n",
    "        return x\n",
    "    pld['new_index_oper'] = pld['index_oper'].apply(from5t6)\n",
    "    pld2['new_index_oper'] = pld2['index_oper'].apply(from5t6)\n",
    "    \n",
    "    pz = pd.merge(pld, qq[['new_index_oper','OPSSUBM','REGION','AUTONOM','CITY','ACTDATE']],how = 'left', on=\"new_index_oper\")\n",
    "    \n",
    "    pld['index_oper'][pz['ACTDATE'].isna() == False]['index_oper'] = pz[pz['ACTDATE'].isna() == False]['new_index_oper'].values\n",
    "    pld2['index_oper'][pz['ACTDATE'].isna() == False]['index_oper'] = pz[pz['ACTDATE'].isna() == False]['new_index_oper'].values\n",
    "    \n",
    "    pld2.loc[pz['ACTDATE'].isna() == False,['OPSSUBM','REGION','AUTONOM','CITY','ACTDATE']] = pz[pz['ACTDATE'].isna() == False][['OPSSUBM','REGION','AUTONOM','CITY','ACTDATE']].values\n",
    "\n",
    "\n",
    "pld2['AREA'] = (pld2['REGION'].fillna('') + pld2['AUTONOM'].fillna('')).values\n",
    "pld2.drop(['REGION','AUTONOM'],axis = 1,inplace = True)\n",
    "pld2.loc[pld2['AREA'] == 'МОСКВА','CITY'] = pld2[pld2['AREA'] == 'МОСКВА']['CITY'].fillna('МОСКВА').values\n",
    "\n",
    "big_test_df = pd.concat([test_df,pld2.drop(['index_oper'],axis=1)],axis = 1)\n",
    "big_test_df['ACTDATE'] = pd.to_datetime(big_test_df['ACTDATE'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npust(x):\n",
    "    if x == '':\n",
    "        return 0\n",
    "    return int(x)\n",
    "big_test_df['index_oper'] = big_test_df['index_oper'].apply(npust)\n",
    "big_test_df['new_index_oper'] = big_test_df['new_index_oper'].apply(npust)\n",
    "big_test_df['OPSSUBM'] = big_test_df['OPSSUBM'].fillna(0).apply(npust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef0cf4",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce84923",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = big_df[['OPSSUBM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = pd.read_csv('zip_to_lat_lon_Europe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = zips[zips['Country'] == 'Russia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = zips[['postal code','latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['OPSSUBM'] = a['OPSSUBM'].astype('str')\n",
    "b = big_df[['new_index_oper']]\n",
    "b['new_index_oper'] = big_df['new_index_oper'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61995632",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips.columns = ['OPSSUBM','latitude','longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb32c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer['latitude'] =wer['latitude'].astype('float64')\n",
    "wer['longitude'] =wer['longitude'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4809cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = pd.DataFrame([['102975', '102976', '420300', '108981', '630874', '200983', '620980','140988', '140960', '130210'],\n",
    "[55.583276,55.583276,55.615,55.58,51.50,59.84,56.50,55.306,55.306,55.3],\n",
    "[37.175359,37.175359,49.268,37.19,35.33,30.425,60.35,37.52,37.52,37.52]]).T\n",
    "\n",
    "wer.columns = ['OPSSUBM','latitude','longitude']\n",
    "zips2 = pd.concat([zips,wer],axis = 0,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.merge(zips2,on = 'OPSSUBM',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "def dist_sha(x):\n",
    "    if np.isnan(x['latitude']):\n",
    "        return np.nan\n",
    "    return geopy.distance.geodesic((x['latitude'],x['longitude']),(55.5832, 37.1753)).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30884bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips2['distance'] = zips2.apply(dist_sha,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43484880",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_tr = ab.apply(dist_sha,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = big_df[['OPSSUBM']]\n",
    "a2['OPSSUBM'] = a2['OPSSUBM'].astype('str')\n",
    "ab2 = a2.merge(zips2,on = 'OPSSUBM',how = 'left')\n",
    "distance_test = ab2.apply(dist_sha,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a788b8c",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af327bc8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_test = pd.read_csv('last_big_test.csv').drop(['Unnamed: 0'],axis = 1)\n",
    "big_train = pd.read_csv('last_big_train.csv').drop(['Unnamed: 0'],axis = 1)\n",
    "text_features = pd.read_csv('new_text_features.csv').drop(['Unnamed: 0'],axis = 1) # Собирается в Pochta_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815717fc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gen_features = pd.read_csv('gen_features.csv') # Собирается в 'pochta6last.ipynb' 'pochta6generate.ipynb' 'pochta6generate+nlp.ipynb'  'pochta6last_last13.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edeb0c8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gen_features = gen_features[['delta_qty_log.MODE(univer.type)','delta_bigi.COUNT(univer)','total_qty_over_index.COUNT(univer)','mailctg.MODE(univer.type)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a42eb0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_big = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d3ab1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cols = [ 'id', 'type', 'weight', 'mailctg', 'mailrank',\n",
    "       'transport_pay', 'postmark', 'weight_mfi', 'price_mfi',\n",
    "       'dist_qty_oper_login_1', 'total_qty_oper_login_1',\n",
    "       'total_qty_oper_login_0', 'total_qty_over_index_and_type',\n",
    "       'total_qty_over_index', 'is_wrong_phone_number', 'op_t',\n",
    "       'op_a', 'CITY', 'AREA', 'net_weight', 'total_price', 'rel_price', 'w/p',\n",
    "       'w*p', 'post_days', 'delta_log1', 'delta_qty_log', 'delta_bigi',\n",
    "       'num_prod', 'cluster', 'mail%0', 'mail%1', 'mail%-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17972162",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "big_train = big_train[cols]\n",
    "big_test = big_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb1287",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_big = pd.concat([big_train,big_test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d5ffc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204ca82",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_big = pd.concat([all_big,pd.concat([text_features.drop(['text'],axis = 1),gen_features],axis = 1)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b234a9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_big.to_csv('all_big.csv') # cluster собирается в pochta2t{i}.ipynb i - [1,10] и pochta3(words).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f217af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dis = pd.concat([big_df[['id','OPSSUBM']],big_test_df[['id','OPSSUBM']]],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e515078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dis['OPSSUBM'] = tt_dis['OPSSUBM'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724117c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt_dis.merge(zips2[['OPSSUBM','distance']],how='left',on='OPSSUBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b079080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.to_csv('/Users/kirillgolubev/PycharmProjects/Pochta/didi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50208a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fea775",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969e818",
   "metadata": {},
   "source": [
    "Сборку приведенных ниже наборов данных можно найти в Auxiliary notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1luhGPR0zWXCmVAsa5tA74e5z9FE63y3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69185d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1mM1Jt3HcwfEx6lVsqbwHiVFQJuW28WV6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1qko7C-EEk1Smf9dB46iSc7DU5kEKIp87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 14mCgEKtF_Z-p6qLkvs-ovM1WtilHy_N-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e839be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1zJeYlt2euRSJi_C25BGyu5LmO1pxPwJt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb575170",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1nUNXbmncyEaimwlhOXpIlhsh8f-MLoEd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ad359",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9066642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3542ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gens = pd.read_csv('../input/end-gen/didi.csv')\n",
    "for i in range(1,7):\n",
    "    ptr = pd.read_csv(f'../input/end-gen/new_gener_{i}.csv')\n",
    "    gens = pd.concat([gens,ptr],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa008bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./all_big.csv')\n",
    "label = pd.read_csv('./label.csv')\n",
    "all_df.drop(['mobile_f', 'AREA', 'post_days', 'num_prod', 'mail%0', 'mail%-1', 'tech_f', 'accses_f', 'man_f',\n",
    "       'cloth_f', 'child_f', 'is_0_mfi','Unnamed: 0'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be600e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([all_df,gens.drop(['Unnamed: 0','id','OPSSUBM'],axis = 1)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab024b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['CITY','type']:\n",
    "    for feat in ['net_weight','weight_mfi','transport_pay','total_price','weight','delta_qty_log','w/p']:\n",
    "        mean = all_df[[col]].merge(all_df[[col,feat]].groupby(col).aggregate('mean'), how = 'left',on=col).fillna(0)[feat]\n",
    "        std = all_df[[col]].merge(all_df[[col,feat]].groupby(col).aggregate('std'), how = 'left',on=col).fillna(1)[feat]\n",
    "        all_df[f'{feat}_{col}'] = (all_df[feat] - mean)/std\n",
    "        print(col,feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.drop(['op_t','op_a'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qty_cols = ['total_qty_over_index','total_qty_over_index_and_type','total_qty_oper_login_0','total_qty_oper_login_1','dist_qty_oper_login_1']\n",
    "for i in range(5):\n",
    "    for j in range(i+1,5):\n",
    "        if (not (i==3 and j==4)) and (not (i ==2  and j==3)) and (not (i == 0 and j == 1)):\n",
    "            all_df[f'delta_{i}_{j}'] =  (all_df[qty_cols[i]] - all_df[qty_cols[j]])\n",
    "            all_df[f'div{i}_{j}'] =  np.log(all_df[qty_cols[i]]+1) - np.log(all_df[qty_cols[j]]+1)\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9718cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def make_bucket(df,feature, n =  100):\n",
    "    '''функция, бьющая на бакеты(по умолчанию 100 точек)'''\n",
    "    return df.assign(bucket = np.ceil(df[feature].rank(pct = True) * n))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_predict1(X_train, y_train, X_test, global_woe):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict_proba(X_train)\n",
    "    return prediction, model.intercept_, model.coef_\n",
    "\n",
    "\n",
    "def woe_val(tar, global_woe, iv, g_t, g_f):\n",
    "    woe = np.log((sum(tar)) / (tar.shape[0] - sum(tar) + 1)) - global_woe\n",
    "    iv += woe * ((sum(tar) / g_t) - (tar.shape[0] - sum(tar)) / g_f)\n",
    "    return woe, iv\n",
    "\n",
    "\n",
    "def woe_line(x, y, n_buckets):  #mid how target feature_name, target_name\n",
    "    \"\"\" Строит график зависимости WoE\n",
    "    x - параметр, от которого стоит искать зависимость\n",
    "    y - метки класса (0 / 1)\n",
    "    n_buckets - количество бинов для вещественного признака\n",
    "    feature_name, target_name - подписи к графику\n",
    "    \"\"\"\n",
    "    ind = np.argsort(x.reshape(-1))\n",
    "    size = len(x) // n_buckets\n",
    "    grouped = []\n",
    "    med_var = []\n",
    "    mini = []\n",
    "    maxi = []\n",
    "    woe = []\n",
    "    iv = 0\n",
    "    df = pd.DataFrame()\n",
    "    df['tar'] = y\n",
    "    df['var'] = x\n",
    "    df = make_bucket(df, 'var', n_buckets)\n",
    "\n",
    "    g_t = sum(y)\n",
    "    g_f = y.shape[0] - g_t\n",
    "\n",
    "    new_nbins = df['bucket'].nunique()\n",
    "    \n",
    "    global_woe = np.log(\n",
    "        (sum(df['tar'].values)) / (df['tar'].shape[0] - sum(df['tar'].values) + 1))\n",
    "    \n",
    "    bucks = np.sort(df['bucket'].unique())\n",
    "    \n",
    "\n",
    "    for t in bucks:\n",
    "        mini.append(np.min(df['var'][df['bucket'] == t]))\n",
    "        maxi.append(np.max(df['var'][df['bucket'] == t]))\n",
    "        med_var.append(np.median(df['var'][df['bucket'] == t]))\n",
    "        w, iv = woe_val(df['tar'][df['bucket'] == t].values, global_woe,\n",
    "                        iv, g_t, g_f)\n",
    "        woe.append(w)\n",
    "        df['bucket'] = df['bucket'].replace(\n",
    "            t, f\"{round(mini[-1],3)}...{round(maxi[-1])}\")\n",
    "\n",
    "    alpha = (med_var[-1] - med_var[0]) / 100\n",
    "\n",
    "    pred, inter, coef = fit_predict1(\n",
    "        x, y,\n",
    "        np.array([med_var[0] - 5 * alpha] + med_var +\n",
    "                 [med_var[-1] + 5 * alpha]).reshape(-1, 1), global_woe)\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    plt.grid()\n",
    "    plt.plot(med_var, woe, 'o', color='red')\n",
    "    line_tar = plt.plot(med_var, woe, color='red', linestyle='--', label=\"Woe\")\n",
    "\n",
    "    log_reg1 = plt.plot([med_var[0], med_var[-1]], [\n",
    "        med_var[0] * coef[0] + inter - global_woe,\n",
    "        med_var[-1] * coef[0] + inter - global_woe\n",
    "    ],\n",
    "                        label=\"Interpolation\")\n",
    "\n",
    "    plt.legend(fontsize=12,\n",
    "               loc='lower right',\n",
    "               fancybox=True,\n",
    "               framealpha=1,\n",
    "               shadow=True)\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "\n",
    "    print(\"IV : \", round(iv, 4))\n",
    "    print(\"AUC : \", round(roc_auc_score(y, pred[:, 1]), 4))\n",
    "    print(\"n_buckets :\", n_buckets)\n",
    "    print(\"The point where woe is zero : \",\n",
    "          round(((global_woe - inter) / coef[0])[0], 4))\n",
    "    print(\"R_sqr : \", round(r2_score(woe,list(map(lambda x: coef[0]*x + inter - global_woe, med_var))),4))\n",
    "    \n",
    "    plt.xlabel(\"Feature\", fontsize=20)\n",
    "    plt.ylabel(\"WoE\", fontsize=20)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    fig = px.histogram(df, x='var', y='tar', color='bucket')\n",
    "    fig.show()\n",
    "\n",
    "def lo_sb(x):\n",
    "    return np.sign(x)*np.log(abs(x)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['w/p_CITY'] = (all_df['w/p_CITY'].clip(lower=-3, upper=3))\n",
    "all_df['mailctg'] = all_df['mailctg'].astype('str')\n",
    "all_df['delta_bigi.COUNT(univer)'] = np.log(all_df['delta_bigi.COUNT(univer)'])\n",
    "all_df['weight'] = np.log(all_df['weight']+1)\n",
    "all_df['delta_0_3'] = np.log(all_df['delta_0_3']+1)\n",
    "all_df['delta_qty_log'] = lo_sb(all_df['delta_qty_log'].clip(-5216249,6753334))\n",
    "all_df['total_qty_over_index.COUNT(univer)'] = np.log(all_df['total_qty_over_index.COUNT(univer)'].clip(1,500000))\n",
    "all_df['delta_qty_log'] = all_df['delta_qty_log'].clip(-100,1000)\n",
    "all_df['net_weight'] = np.abs(lo_sb(all_df['net_weight'].clip(-100,1000))).values\n",
    "all_df['total_price_CITY'] = all_df['total_price_CITY'].fillna(0).clip(-1,1)\n",
    "all_df['div0_4'] = all_df['div0_4'].clip(0,12)\n",
    "all_df['net_weight_CITY'] = all_df['net_weight_CITY'].fillna(0).clip(-5,5)\n",
    "all_df['delta_1_2'] = make_bucket(all_df[['delta_1_2']],'delta_1_2')['bucket']\n",
    "all_df['delta_0_2'] = make_bucket(all_df[['delta_0_2']],'delta_0_2')['bucket']\n",
    "all_df['total_price_type'] = all_df['total_price_type'].clip(-2,2)\n",
    "all_df['price_mfi'] = all_df['price_mfi'].clip(0,1500)\n",
    "all_df['weight_type'] = np.sqrt(all_df['weight_type'].fillna(0).clip(-0.7,2)+0.7)\n",
    "all_df['cluster'] = all_df['cluster'].astype('str')\n",
    "all_df['div1_4'] = all_df['div1_4'].fillna(0).clip(5,11)\n",
    "all_df['transport_pay_CITY'] = all_df['transport_pay_CITY'].fillna(0).clip(-1,3)\n",
    "all_df['transport_pay_type'] = all_df['transport_pay_type'].fillna(0).clip(-0.5,4)\n",
    "all_df['delta_qty_log_type'] = all_df['delta_qty_log_type'].fillna(0).clip(-2,2)\n",
    "all_df['net_weight_type'] = all_df['net_weight_type'].fillna(0).clip(-2,2)\n",
    "all_df['weight_mfi_CITY'] = all_df['weight_mfi_CITY'].fillna(0).clip(-1,3)\n",
    "all_df['w/p_type'] = all_df['w/p_type'].fillna(0).clip(-3,3)\n",
    "all_df['weight_CITY'] = np.log(all_df['weight_CITY'].fillna(0).clip(-1,2) +2)\n",
    "all_df['w/p'] = all_df['w/p'].fillna(0).clip(-3,2)\n",
    "all_df['div0_3'] = all_df['div0_3'].fillna(0).clip(0,4)\n",
    "all_df['delta_qty_log_CITY'] = all_df['delta_qty_log_CITY'].fillna(0).clip(-3,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c611fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bum = ['weight', 'mailrank', 'transport_pay', 'postmark', 'weight_mfi',\n",
    "       'price_mfi', 'dist_qty_oper_login_1', 'total_qty_oper_login_1',\n",
    "       'total_qty_oper_login_0', 'total_qty_over_index_and_type',\n",
    "       'total_qty_over_index', 'is_wrong_phone_number', 'net_weight',\n",
    "       'total_price', 'rel_price', 'w/p', 'w*p', 'delta_log1', 'delta_qty_log',\n",
    "       'delta_bigi', 'mail%1', 'delta_bigi.COUNT(univer)',\n",
    "       'total_qty_over_index.COUNT(univer)', 'distance',\n",
    "       'CITY.MEAN(univer.weight_type)', 'CITY.STD(univer.delta_1_2)',\n",
    "       'net_weight.MAX(univer.w*p)', 'rel_price.SKEW(univer.weight_type)',\n",
    "       'rel_price.STD(univer.weight_type)', 'w*p.SKEW(univer.weight_type)',\n",
    "       'net_weight_CITY', 'weight_mfi_CITY', 'transport_pay_CITY',\n",
    "       'total_price_CITY', 'weight_CITY', 'delta_qty_log_CITY', 'w/p_CITY',\n",
    "       'net_weight_type', 'weight_mfi_type', 'transport_pay_type',\n",
    "       'total_price_type', 'weight_type', 'delta_qty_log_type', 'w/p_type',\n",
    "       'delta_0_2', 'div0_2', 'delta_0_3', 'div0_3', 'delta_0_4', 'div0_4',\n",
    "       'delta_1_2', 'div1_2', 'delta_1_3', 'div1_3', 'delta_1_4', 'div1_4',\n",
    "       'delta_2_4', 'div2_4']\n",
    "for col in bum:\n",
    "    all_df[col] = all_df[col].fillna(0).clip(np.percentile(all_df[col].fillna(0).values, 1),np.percentile(all_df[col].fillna(0).values, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['dist/price'] = np.log(all_df['distance']+1) - np.log(all_df['total_price']+1)\n",
    "all_df['dist/weight'] = np.log(all_df['distance']+1) - np.log(all_df['weight']+1)\n",
    "\n",
    "all_df['dist*price_log'] = np.log(all_df['distance']*all_df['total_price']+1)\n",
    "all_df['dist*weight'] = all_df['distance']*all_df['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bum1 = ['dist/price', 'dist/weight', 'dist*price_log']\n",
    "for col in bum1:\n",
    "    all_df[col] = all_df[col].fillna(0).clip(np.percentile(all_df[col].fillna(0).values, 1),np.percentile(all_df[col].fillna(0).values, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train = all_df[:6000000]\n",
    "big_test = all_df[6000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 32\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 900*4*2 # equal to 15*4 minutes\n",
    "TARGET_NAME = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeaf609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    big_train, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f'Data splitted. Parts sizes: tr_data = {tr_data.shape}, te_data = {te_data.shape}')\n",
    "\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd049e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['w/p', 'delta_qty_log.MODE(univer.type)', 'w*p',\n",
    "       'rel_price.SKEW(univer.weight_type)', 'mailctg', 'weight_type',\n",
    "       'weight_mfi_type', 'w*p.SKEW(univer.weight_type)', 'dist/price',\n",
    "       'type', 'net_weight_type', 'div0_2', 'delta_bigi.COUNT(univer)',\n",
    "       'total_qty_over_index.COUNT(univer)', 'delta_0_3', 'w/p_CITY',\n",
    "       'delta_qty_log', 'weight_mfi_CITY', 'rel_price',\n",
    "       'delta_qty_log_type', 'delta_1_2', 'net_weight.MAX(univer.w*p)',\n",
    "       'net_weight_CITY', 'rel_price.STD(univer.weight_type)',\n",
    "       'weight_mfi', 'is_wrong_phone_number', 'total_price_CITY',\n",
    "       'total_price_type', 'delta_bigi', 'transport_pay_CITY', 'cluster',\n",
    "       'weight_CITY', 'price_mfi', 'net_weight', 'delta_0_2',\n",
    "       'dist/weight', 'div0_3', 'transport_pay_type', 'CITY',\n",
    "       'dist*price_log', 'div0_4', 'dist_qty_oper_login_1', 'delta_log1',\n",
    "       'div1_4', 'CITY.STD(univer.delta_1_2)', 'mail%1',\n",
    "       'mailctg.MODE(univer.type)', 'weight', 'delta_1_3', 'div1_2',\n",
    "       'delta_qty_log_CITY', 'div2_4', 'div1_3', 'dist*weight',\n",
    "       'transport_pay', 'w/p_type', 'distance',\n",
    "       'CITY.MEAN(univer.weight_type)', 'delta_1_4', 'total_price','id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13465b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('binary',loss = 'logloss',metric = 'logloss') #task = Task('binary', loss = 'logloss', metric = 'auc')\n",
    "\n",
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "    'drop': ['id']\n",
    "}\n",
    "\n",
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600*6,\n",
    "    cpu_limit = N_THREADS,\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "oof_pred = automl.fit_predict(big_train, roles = roles,verbose=2)\n",
    "not_nan = np.any(~np.isnan(oof_pred.data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(automl, 'model_end.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903746d",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = joblib.load('model_end.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_test_pred = automl.predict(big_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns = ['id','label'])\n",
    "submission['id'] = big_test['id'].values\n",
    "submission['label'] = 1*(end_test_pred.data[:,0] >= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('submission_17_galactica_001.csv.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (DLOFhw2)",
   "language": "python",
   "name": "pycharm-9d5589ca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
